{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXATwZ8VxZG7",
    "tags": []
   },
   "source": [
    "# Relatório Hands-On-1\n",
    "\n",
    "Fernando Antonio Marques Schettini $^1$, Gabriel Mascarenhas Costa de Sousa$^2$, Jadson Nobre das Virgens$^2$\n",
    "\n",
    "$^1$ Curso de Engenharia de Computação - Centro universitário SENAI CIMATEC, Salvador, Bahia, Brazil  \n",
    "\n",
    "$^2$ Curso de Sistemas de Informação - Universidade do Estado da Bahia, Salvador, Bahia, Brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5PcGb-Pt0_j"
   },
   "source": [
    "# Resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orxl23v_xqVe"
   },
   "source": [
    "Este é o relátorio das atividades realizadas durante a execução da prática Hands-On-1$^{[1]}$. O relatório foi feito como atividade avaliativa da matéria Fundamentos de Programação Paralela, lecionada no centro universitário SENAI CIMATEC. \n",
    "\n",
    "A prática Hands-On-1, dividida em 2 seções, tem o objetivo de introduzir conceitos de programação paralela através da aplicação das técnicas de paralelização utilizando a bilbioteca OPENMP em códigos em C para a otimização do tempo de execução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGlWZ-SlQObx"
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngiuqnkbvTdx"
   },
   "source": [
    "Na sessão um, somos apresentados a uma situação problema: Multiplicação de Matrizes. Um código de multiplicação de matrizes é problemático em relação ao tempo de execução, já que o número de operações cresce de forma exponecial a medida em que o aumentamos o tamanho das matrizes, característico de um algoritmo de complexidade O(n$^2$). Por isso, nessa sessão utilizamos a biblioteca OPENMP para dividir os loops responsáveis pela multiplicação dos itens entre as threads do processador.\n",
    "\n",
    "Fazendo um profilling do código, podemos localizar os pontos aonde o código demora mais. Para isso, primeiro compilamos o código, executamos, e utilizamos a ferramenta gprof para nos fornecer uma ánalise sobre a relação entre as partes do código e seus respectivos tempos de execução:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yp3JWwL2BhxG"
   },
   "outputs": [],
   "source": [
    "!gcc mm.c -o mm -fopenmp -pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VRMEJ1cxBhxG",
    "outputId": "46f11903-337b-49d7-ad95-7274d747f693",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t1.621535\r\n"
     ]
    }
   ],
   "source": [
    "!./mm 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QuZ5ZdebBhxI",
    "outputId": "b3d8fcb6-3df3-454e-e562-daec39dffa0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat profile:\r\n",
      "\r\n",
      "Each sample counts as 0.01 seconds.\r\n",
      "  %   cumulative   self              self     total           \r\n",
      " time   seconds   seconds    calls  ms/call  ms/call  name    \r\n",
      " 99.73      4.17     4.17                             main\r\n",
      "  0.48      4.19     0.02        2    10.08    10.08  initializeMatrix\r\n",
      "\f",
      "\r\n",
      "\t\t\tCall graph\r\n",
      "\r\n",
      "\r\n",
      "granularity: each sample hit covers 2 byte(s) for 0.24% of 4.19 seconds\r\n",
      "\r\n",
      "index % time    self  children    called     name\r\n",
      "                                                 <spontaneous>\r\n",
      "[1]    100.0    4.17    0.02                 main [1]\r\n",
      "                0.02    0.00       2/2           initializeMatrix [2]\r\n",
      "-----------------------------------------------\r\n",
      "                0.02    0.00       2/2           main [1]\r\n",
      "[2]      0.5    0.02    0.00       2         initializeMatrix [2]\r\n",
      "-----------------------------------------------\r\n",
      "\f",
      "\r\n",
      "Index by function name\r\n",
      "\r\n",
      "   [2] initializeMatrix        [1] main\r\n"
     ]
    }
   ],
   "source": [
    "!gprof -b mm gmon.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hlLZdW5P2_b"
   },
   "source": [
    "Como o esperado, os três laços responsáveis pela operação da multiplicação, são a parte do código que levam mais tempo para serem executadas, por isso, aplicaremos as técnicas de paralelização. \n",
    "\n",
    "Na sessão 2, temos um código que basea-se na otimização de multiplicação de itens dentro de uma matriz por coeficientes específicos, repartindo o trabalho entre as threads numa mesma matriz e simulando a execução de uma tarefa assíncrona. Inicialmente, o código apenas multiplica uma parte da matriz utilizando só 2 threads. Logo, nossa tarefa para essa seção é ultilizar 5 threads em paralelo, desta forma, multiplicando o resto dos elementos da matriz, por coeficientes diferentes. Nesta sessão é importante manter o paradigma da memória compartilhada em mente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWbtdBgpwXeJ"
   },
   "source": [
    "# Resultados e Discussões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56kMBoGq8FSA"
   },
   "source": [
    "## Seção 1 - Multiplicação de matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usDLg1B_BhxK"
   },
   "source": [
    "Começamos o processo de paralelização do código definindo os laços que executam a multiplicação entre as matrizes dentro de uma região paralela, logo depois, adicionamos mais uma técnica de profilling dentro do código capturando os tempos de início e término da multiplicação dentro das váriaveis t1 e t2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqLlZjUcBhxK"
   },
   "outputs": [],
   "source": [
    "t1 = omp_get_wtime(); //Tempo quando loops iniciam\n",
    "  \n",
    "//Multiplicação de matrizes\n",
    "#pragma omp parallel for private(i, j, k) // Comando para paralelização dos loops \n",
    "for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "        for(k = 0; k < size; k++)\n",
    "            C[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "            \n",
    "t2 = omp_get_wtime(); //Tempo quando os loops acabam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxdU034hBhxL"
   },
   "source": [
    "Dentro dessa região, o código será paralelizado automaticamente privando as variáveis i, j e k, além disso também temos acesso ao tempo deste processo, diminuindo t1-t2 e imprimindo no terminal. No final do processo de paralelização teremos um código parecido com esse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSjLfIpSBhxL",
    "outputId": "0cdb695f-2cb6-4b42-cb47-8d2fa006cbf2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.000000\r\n"
     ]
    }
   ],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void initializeMatrix(int *matrix, int size) //Preenche a matrix com numeros aleatorios\n",
    "{\n",
    "  for (int i = 0; i < size; i++)\n",
    "    for (int j = 0; j < size; j++)\n",
    "      matrix[i * size + j] = rand() % (10 - 1) * 1;\n",
    "}\n",
    "\n",
    "void printMatrix(int *matrix, int size) //Percorre a Matrix, printando ela\n",
    "{\n",
    "  for (int i = 0; i < size; i++)\n",
    "  {\n",
    "    for (int j = 0; j < size; j++)\n",
    "      printf(\"%d\\t\", matrix[i * size + j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main (int argc, char **argv)\n",
    "{\n",
    " \n",
    "  //Define as variáveis\n",
    "  int size = atoi(argv[1]);  \n",
    "  int i, j, k;\n",
    "  double t1, t2;\n",
    "\n",
    "  //Aloca as matrizes\n",
    "  int  *A = (int *) malloc (sizeof(int)*size*size);\n",
    "  int  *B = (int *) malloc (sizeof(int)*size*size);\n",
    "  int  *C = (int *) malloc (sizeof(int)*size*size);\n",
    " \n",
    "  //Preenche matrizes com numeros aleatorios\n",
    "  initializeMatrix(A, size);\n",
    "  initializeMatrix(B, size);\n",
    "\n",
    "  t1 = omp_get_wtime(); //Tempo quando os loops iniciam\n",
    "  \n",
    "  //Multiplicação de matrizes\n",
    "  #pragma omp parallel for private(i, j, k) // Comando para paralelização de loops \n",
    "    for(i = 0; i < size; i++)\n",
    "      for(j = 0; j < size; j++)\n",
    "        for(k = 0; k < size; k++)\n",
    "          C[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    " \n",
    "  t2 = omp_get_wtime(); //Tempo quando os loops acabam\n",
    " \n",
    "  //Printa matrizes\n",
    "  //printMatrix(A,size);\n",
    "  //printMatrix(B,size);\n",
    "  //printMatrix(C,size);\n",
    " \n",
    "  //Printa tamanho da matriz e tempo para multiplicação\n",
    "  printf(\"%d\\t%f\\n\",size,t2-t1);\n",
    "\n",
    "  return 0;\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdj9EdYH4RMS"
   },
   "source": [
    "Como proposto na prática, para confirmar e homologar a efetividade da paralelização de um código, precisamos comparar o código paralelizado ao original, não paralelizado. Para isso, o grupo usa um script para automatizar o processo, executando o código várias vezes, variando o número de threads e tamanho das matrizes, desta forma, coletando os dados e construindo os gráficos relacionais entre speedup do problema e número de threads e número de threads com velocidade de execução. Para executar o script basta executar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2qsH0ZZBhxM"
   },
   "outputs": [],
   "source": [
    "!bash START.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOXpKoRrJ5sm"
   },
   "source": [
    "### Gráfico relacional entre tamanho da matriz e speedup do problema:\n",
    "\n",
    "![Figure 1](https://user-images.githubusercontent.com/80331486/187289071-c89579df-b985-4dcb-849a-f3150c41aa9a.png)\n",
    "\n",
    "No primeiro gráfico, podemos observar a relação entre speedup e tamanho das matrizes, em geral, 4 threads se mostra com uma taxa de speedup melhor, ficando para trás em poucos casos.\n",
    "\n",
    "### Gráfico relacional entre tempo de execução e tamanho das matrizes:\n",
    "\n",
    "![Figure 2](https://user-images.githubusercontent.com/80331486/187289256-d6a171c4-616f-47fd-b2cf-310f6295e9dd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1OAPJPiBhxN"
   },
   "source": [
    "No segundo gráfico, podemos ver o tempo de execução caindo, conforme o número de threads aumenta, em paralelo, o tempo de execução subindo, conforme o tamanho das matrizes cresce. Segundo a teoria$^{[2]}$, existe um número ideal de threads tal que aumenta esse número representaria um aumento no tempo de execução, no entanto, numa máquina com poucas threads é díficil estimar este número ideal, mas segundo o gráfico, 4 threads é o número com maior eficiêcia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4kcvCMeBhxN"
   },
   "source": [
    "## Seção 2 - Tarefas Assíncronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6N2ZHB0BhxN"
   },
   "source": [
    "Executando o código fornecido inicialmente pela prática com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyEXxjQtBhxO"
   },
   "outputs": [],
   "source": [
    "!gcc asyncTaskOpenMP.c -o asyncTaskOpenMP -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7q7i5WHSBhxO"
   },
   "outputs": [],
   "source": [
    "!./asyncTaskOpenMP 10 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6PuGAQxBhxO"
   },
   "source": [
    "Ele imprime uma matriz 10x10 preenchida cincos, mais abaixo, ele imprime novamente a mesma matriz, agora com as quatro primeiras colunas mutiplicadas por 10 e 20. Estudando o funcionamento do código percebemos que dentro da área de paralelização, o código pega o id da threads que está executando o chunck e baseado nisso, determina através de condicionais para ditar oquê cada thread deve ou não fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYlKcu8XBhxO"
   },
   "outputs": [],
   "source": [
    "//Criando área de paralelização, privando row e column\n",
    "#pragma omp parallel private(row, column)\n",
    "  {\n",
    "    int id = omp_get_thread_num();\n",
    "\n",
    "    if(id == 0) // Condicional para a thread de id de número 0\n",
    "    {\n",
    "      //Multiplicação das colunas por k1\n",
    "      for(row = 0; row < n; row++)\n",
    "        for(column = 0; column < block_size; column++)\n",
    "          matrix[row][column] *= k1;\n",
    "    }\n",
    "\n",
    "    if(id == 1) // Condicional para a thread de id de número 1\n",
    "    {\n",
    "      //Multiplicação das colunas por k2\n",
    "      for(row = 0; row < n; row++)\n",
    "        for(column = block_size; column < block_size*2; column++)\n",
    "          matrix[row][column] *= k2;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay20X84cBhxP"
   },
   "source": [
    "Baseado nisso, o grupo usa a mesma tática, mas agora para utilizar 3 outras threads na operação com outros coeficientes em outras colunas. No final, obtemos o seguinte código:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqXggXvuBhxP"
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "#define SIZE_MATRIX 10\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  //Definido as váriaveis\n",
    "  int n = atoi(argv[1]);\n",
    "  int block_size = atoi(argv[2]);\n",
    "  int matrix[n][n], k1 = 10, k2 = 20, k3 = 30,k4 = 40,k5 = 50;\n",
    "  int i, j, row, column;\n",
    "\n",
    "  //Preenchendo e imprimindo a matriz\n",
    "  for(i = 0; i < n; i++)\n",
    "  {\n",
    "    for(j = 0; j < n; j++)\n",
    "    {\n",
    "      matrix[i][j] = 5;\n",
    "      printf(\"%d\\t\", matrix[i][j]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\\n\");\n",
    "\n",
    "  //Definindo o número de threds\n",
    "  omp_set_num_threads(5);\n",
    "\n",
    "  //Criando área de paralelização, privando row e column\n",
    "  #pragma omp parallel private(row, column)\n",
    "  {\n",
    "    int id = omp_get_thread_num();\n",
    "\n",
    "    if(id == 0) // Condicional para a thread de id de número 0\n",
    "    {\n",
    "      //Multiplicação das colunas por k1\n",
    "      for(row = 0; row < n; row++)\n",
    "        for(column = 0; column < block_size; column++)\n",
    "          matrix[row][column] *= k1;\n",
    "    }else{\n",
    "      if(id == 1){// Condicional para a thread de id de número 1\n",
    "        //Multiplicação das colunas por k2\n",
    "        for(row = 0; row < n; row++)\n",
    "          for(column = block_size; column < block_size*2; column++)\n",
    "            matrix[row][column] *= k2;\n",
    "      }else{\n",
    "        if(id == 2){ // Condicional para a thread de id de número 2\n",
    "          //Multiplicação das colunas por k3\n",
    "          for(row = 0; row < n; row++)\n",
    "            for(column = block_size*2; column < block_size*3; column++)\n",
    "              matrix[row][column] *= k3;\n",
    "        }else{\n",
    "          if(id == 3){ // Condicional para a thread de id de número 3\n",
    "            //Multiplicação das colunas por k4\n",
    "            for(row = 0; row < n; row++)\n",
    "              for(column = block_size*3; column < block_size*4; column++)\n",
    "                matrix[row][column] *= k4;\n",
    "          }else{\n",
    "            if(id == 4){ // Condicional para a thread de id de número 4\n",
    "              //Multiplicação das colunas por k5\n",
    "              for(row = 0; row < n; row++)\n",
    "                for(column = block_size*4; column < block_size*5; column++)\n",
    "                  matrix[row][column] *= k5;\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  //Imprimindo matriz resultante\n",
    "  for(i = 0; i < n; i++)\n",
    "  {\n",
    "    for(j = 0; j < n; j++)\n",
    "      printf(\"%d\\t\", matrix[i][j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkFzAmE4BhxP"
   },
   "source": [
    "Compilando e executando novamente esse código, obtemos uma matrizes com todas as colunas com multiplos de 5: 10, 20,30,40,50, onde cada threads executou uma dupla de colunas diferente, ao mesmo tempo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EkecWU4KKvo"
   },
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpWPbNriBhxQ"
   },
   "source": [
    "Para resumir, durante a execução das práticas o grupo desenvolveu habilidades relacionadas ao uso da biblioteca OPENMP em problemas simples de otimização de código, criação de scripts em shellscript e análise de dados. Atráves da primeira sessão, observa-se na prática que o tempo de execução caí de acordo com o aumento do número de threads utilizadas no processo, enquanto na segunda sessão experimentamos um maior domíniom das threads repartindo manualmente as tarefas de cada uma. Portando, a prática HANDS-ON-1 foi um pontapé inicial para os estudos de programação paralela, estabelecendo conceitos básicos e iniciando o processo de otimização de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLvw8lasJ9yZ"
   },
   "source": [
    "# Reconhecimentos\n",
    "Todo o conceito da prática e orientação para o desenvolvimento da atividade foi realizada pelo professor Murillo Boratto, pesquisador do centro de supercomputação SENAI CIMATEC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbxAR_nZ3ey8"
   },
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHs1Te143ezA"
   },
   "source": [
    "[1] M. Boratto. Hands-On Supercomputing with Parallel Computing. Available: https://github.com/\n",
    "muriloboratto/Hands-On-Supercomputing-with-Parallel-Computing. 2022.\n",
    "\n",
    "[2] B. Chapman, G. Jost and R. Pas. Using OpenMP: Portable Shared Memory Parallel Programming. The\n",
    "MIT Press, 2007, USA."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-T1_3R6iCaFL",
    "BF4BYJbRK3dk",
    "gLAY9cBjxrjs",
    "0MiGCjRsrn9m",
    "tODCNPjB9eGn",
    "u9P77BloNxg7",
    "MNXuoP6ROAvo",
    "GmH0n7r1PVbM",
    "L5kUBzMXvW3z",
    "HYIuvShRPBvo",
    "7-PpumH1KDAH",
    "xbA7sVD4x_Mj"
   ],
   "name": "Relatório_Prática_Hands_On_1_Fernando_Gabriel_Jadson.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/jupyter-papers/mock-paper/blob/master/FerroicBlocks_mockup_paper_v3a.ipynb",
     "timestamp": 1659115650450
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
