{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXATwZ8VxZG7",
    "tags": []
   },
   "source": [
    "# Relatório Hands-On-1\n",
    "\n",
    "Fernando Antonio Marques Schettini $^1$, Gabriel Mascarenhas Costa de Sousa$^2$, Jadson Nobre das Virgens$^2$\n",
    "\n",
    "$^1$ Curso de Engenharia de Computação - Centro universitário SENAI CIMATEC, Salvador, Bahia, Brazil  \n",
    "\n",
    "$^2$ Curso de Sistemas de Informação - Universidade do Estado da Bahia, Salvador, Bahia, Brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5PcGb-Pt0_j"
   },
   "source": [
    "# Resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orxl23v_xqVe"
   },
   "source": [
    "<p> Este é o relátorio das atividades realizadas durante a execução na prática Hands-On-1. O relatório foi feito como atividade avaliativa da matéria Fundamentos de Programação Paralela, lecionada no centro universitário SENAI CIMATEC. </p>\n",
    "\n",
    "<p> A prática Hands-On-1, dividida em 2 seções, tem o objetivo de introduzir conceitos de programação paralela através da aplicação das técnicas de paralelização utilizando a bilbioteca OPENMP em códigos C/C++ para a otimização do tempo de execução. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGlWZ-SlQObx",
    "tags": []
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngiuqnkbvTdx"
   },
   "source": [
    "A primeira sessão apresenta o problema algoritmo de <b> Multiplicação de Matrizes </b>. Dado um código genérico, o mesmo imprime o resultado da multiplicação matricial. A idéia base desta prática é melhorar os tempos de execuções através da API OPENMP dividindo as cargas de trabalho entre as threads em execuções concorrentes no recurso computacional multiprocessador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> A etapa inicial consiste em fazer a contagem periódica do estado da  aplicação sequencial, a qual denominamos <b>profilling</b>. Utilizaremos uma ferramenta chamada GPROF, e para isso, compilaremos e executaremos com uma flag que mapeará os custos computacionais utilizados.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yp3JWwL2BhxG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clang: \u001b[0;1;31merror: \u001b[0m\u001b[1munsupported option '-fopenmp'\u001b[0m\n",
      "clang: \u001b[0;1;31merror: \u001b[0m\u001b[1mthe clang compiler does not support -pg option on versions of OS X 10.9 and later\u001b[0m\n",
      "clang: \u001b[0;1;31merror: \u001b[0m\u001b[1munsupported option '-fopenmp'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!gcc mm.c -o mm -fopenmp -pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VRMEJ1cxBhxG",
    "outputId": "46f11903-337b-49d7-ad95-7274d747f693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: ./mm: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./mm 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QuZ5ZdebBhxI",
    "outputId": "b3d8fcb6-3df3-454e-e562-daec39dffa0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat profile:\n",
      "\n",
      "Each sample counts as 0.01 seconds.\n",
      "  %   cumulative   self              self     total           \n",
      " time   seconds   seconds    calls  ms/call  ms/call  name    \n",
      " 99.73      4.17     4.17                             main\n",
      "  0.48      4.19     0.02        2    10.08    10.08  initializeMatrix\n",
      "\f",
      "\n",
      "\t\t\tCall graph\n",
      "\n",
      "\n",
      "granularity: each sample hit covers 2 byte(s) for 0.24% of 4.19 seconds\n",
      "\n",
      "index % time    self  children    called     name\n",
      "                                                 <spontaneous>\n",
      "[1]    100.0    4.17    0.02                 main [1]\n",
      "                0.02    0.00       2/2           initializeMatrix [2]\n",
      "-----------------------------------------------\n",
      "                0.02    0.00       2/2           main [1]\n",
      "[2]      0.5    0.02    0.00       2         initializeMatrix [2]\n",
      "-----------------------------------------------\n",
      "\f",
      "\n",
      "Index by function name\n",
      "\n",
      "   [2] initializeMatrix        [1] main\n"
     ]
    }
   ],
   "source": [
    "!gprof -b mm gmon.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hlLZdW5P2_b"
   },
   "source": [
    "Como o esperado, os três laços responsáveis pela operação da multiplicação, são a parte do código que possuem o maior custo computacional da aplicação, por isso, aplicaremos à esta região técnicas de paralelização. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWbtdBgpwXeJ"
   },
   "source": [
    "# Resultados e Discussões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56kMBoGq8FSA"
   },
   "source": [
    "## Seção 1 - Multiplicação de matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usDLg1B_BhxK"
   },
   "source": [
    "<p> Começamos o processo de paralelização do código definindo os laços que executam a multiplicação entre as matrizes dentro de uma região paralela, logo depois, mensuramos os tempos de execução desta parte específica a partir das váriaveis t1 e t2 </p>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqLlZjUcBhxK"
   },
   "outputs": [],
   "source": [
    "t1 = omp_get_wtime(); \n",
    "  \n",
    "#pragma omp parallel for private(i, j, k) \n",
    "for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "        for(k = 0; k < size; k++)\n",
    "            C[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    "            \n",
    "t2 = omp_get_wtime(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxdU034hBhxL"
   },
   "source": [
    "Dentro dessa região, o código será paralelizado de forma automática, tendo como variáveis privadas i, j, e k e C, A e B compartilhadas. Ao final do processo teremos o seguinte código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSjLfIpSBhxL",
    "outputId": "0cdb695f-2cb6-4b42-cb47-8d2fa006cbf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.000000\n"
     ]
    }
   ],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void initializeMatrix(int *matrix, int size) \n",
    "{\n",
    "  for (int i = 0; i < size; i++)\n",
    "    for (int j = 0; j < size; j++)\n",
    "      matrix[i * size + j] = rand() % (10 - 1) * 1;\n",
    "}\n",
    "\n",
    "void printMatrix(int *matrix, int size) \n",
    "{\n",
    "  for (int i = 0; i < size; i++)\n",
    "  {\n",
    "    for (int j = 0; j < size; j++)\n",
    "      printf(\"%d\\t\", matrix[i * size + j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main (int argc, char **argv)\n",
    "{\n",
    "  int size = atoi(argv[1]);  \n",
    "  int i, j, k;\n",
    "  double t1, t2;\n",
    "\n",
    "  int  *A = (int *) malloc (sizeof(int)*size*size);\n",
    "  int  *B = (int *) malloc (sizeof(int)*size*size);\n",
    "  int  *C = (int *) malloc (sizeof(int)*size*size);\n",
    " \n",
    "  initializeMatrix(A, size);\n",
    "  initializeMatrix(B, size);\n",
    "\n",
    "  t1 = omp_get_wtime(); \n",
    "  \n",
    "  #pragma omp parallel for private(i, j, k)  \n",
    "  for(i = 0; i < size; i++)\n",
    "    for(j = 0; j < size; j++)\n",
    "       for(k = 0; k < size; k++)\n",
    "          C[i * size + j] += A[i * size + k] * B[k * size + j];\n",
    " \n",
    "  t2 = omp_get_wtime();\n",
    " \n",
    "  printf(\"%d\\t%f\\n\",size,t2-t1);\n",
    "\n",
    "  return 0;\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdj9EdYH4RMS"
   },
   "source": [
    "<p> Como proposto na prática, para confirmar e homologar a efetividade da paralelização de um código, precisamos comparar o código paralelizado em detrimento ao original denominado sequencial. Para isso, criamos um script para automatizar o processo de execução para múltiplos tamanhos do problema, variando o número de threads. Desta forma, coletando os dados experimentais teremos como resultados: gráficos de desempenho para os tempos de execução e speedup em função do tamanho do problema. Para executar o script basta executar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2qsH0ZZBhxM"
   },
   "outputs": [],
   "source": [
    "!bash START.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOXpKoRrJ5sm"
   },
   "source": [
    "### Gráfico relacional entre tamanho da matriz e speedup do problema:\n",
    "\n",
    "![Figure 1](https://user-images.githubusercontent.com/80331486/187289071-c89579df-b985-4dcb-849a-f3150c41aa9a.png)\n",
    "\n",
    "No primeiro gráfico, podemos observar a relação entre speedup e tamanho das matrizes, em geral, 4 threads se mostra com uma taxa de speedup melhor, ficando para trás em poucos casos.\n",
    "\n",
    "### Gráfico relacional entre tempo de execução e tamanho das matrizes:\n",
    "\n",
    "![Figure 2](https://user-images.githubusercontent.com/80331486/187289256-d6a171c4-616f-47fd-b2cf-310f6295e9dd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1OAPJPiBhxN"
   },
   "source": [
    "No segundo gráfico, podemos ver o tempo de execução caindo, conforme o número de threads aumenta, em paralelo, o tempo de execução subindo, conforme o tamanho das matrizes cresce. Segundo a teoria$^{[2]}$, existe um número ideal de threads tal que aumenta esse número representaria um aumento no tempo de execução, no entanto, numa máquina com poucas threads é díficil estimar este número ideal, mas segundo o gráfico, 4 threads é o número com maior eficiêcia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4kcvCMeBhxN"
   },
   "source": [
    "## Seção 2 - Tarefas Assíncronas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6N2ZHB0BhxN"
   },
   "source": [
    "Executando o código fornecido inicialmente pela prática teremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyEXxjQtBhxO"
   },
   "outputs": [],
   "source": [
    "!gcc asyncTaskOpenMP.c -o asyncTaskOpenMP -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7q7i5WHSBhxO"
   },
   "outputs": [],
   "source": [
    "!./asyncTaskOpenMP 10 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6PuGAQxBhxO"
   },
   "source": [
    "A saída do resultado expressa a impressão de uma representação matricial de ordem 10 com tamanho de bloco de valor 2, imprime o acrescimento aos valores para as constantes k1 e k2. Observando o funcionamento do código percebemos que  das 5 threads inicializadas somente as duas iniciais realizam trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYlKcu8XBhxO"
   },
   "outputs": [],
   "source": [
    "#pragma omp parallel private(row, column)\n",
    "  {\n",
    "    int id = omp_get_thread_num();\n",
    "\n",
    "    if(id == 0) \n",
    "    {\n",
    "      for(row = 0; row < n; row++)\n",
    "        for(column = 0; column < block_size; column++)\n",
    "          matrix[row][column] *= k1;\n",
    "    }\n",
    "\n",
    "    if(id == 1) \n",
    "    {\n",
    "      for(row = 0; row < n; row++)\n",
    "        for(column = block_size; column < block_size*2; column++)\n",
    "          matrix[row][column] *= k2;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay20X84cBhxP"
   },
   "source": [
    "Com isso, a tarefa resume-se a expandir o mesmo trabalho às outras threads. Sendo, constituindo o seguinte código:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqXggXvuBhxP"
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "#define SIZE_MATRIX 10\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int n = atoi(argv[1]);\n",
    "  int block_size = atoi(argv[2]);\n",
    "  int matrix[n][n], k1 = 10, k2 = 20, k3 = 30, k4 = 40, k5 = 50;\n",
    "  int i, j, row, column;\n",
    "\n",
    "  for(i = 0; i < n; i++)\n",
    "  {\n",
    "    for(j = 0; j < n; j++)\n",
    "    {\n",
    "      matrix[i][j] = 5;\n",
    "      printf(\"%d\\t\", matrix[i][j]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\\n\");\n",
    "\n",
    "  omp_set_num_threads(5);\n",
    "\n",
    "  #pragma omp parallel private(row, column)\n",
    "  {\n",
    "    int id = omp_get_thread_num();\n",
    "\n",
    "    if(id == 0) \n",
    "    {\n",
    "      for(row = 0; row < n; row++)\n",
    "        for(column = 0; column < block_size; column++)\n",
    "          matrix[row][column] *= k1;\n",
    "    }else{\n",
    "      if(id == 1){\n",
    "        for(row = 0; row < n; row++)\n",
    "          for(column = block_size; column < block_size*2; column++)\n",
    "            matrix[row][column] *= k2;\n",
    "      }else{\n",
    "        if(id == 2){ \n",
    "          for(row = 0; row < n; row++)\n",
    "            for(column = block_size*2; column < block_size*3; column++)\n",
    "              matrix[row][column] *= k3;\n",
    "        }else{\n",
    "          if(id == 3){ \n",
    "            for(row = 0; row < n; row++)\n",
    "              for(column = block_size*3; column < block_size*4; column++)\n",
    "                matrix[row][column] *= k4;\n",
    "          }else{\n",
    "            if(id == 4){ \n",
    "              for(row = 0; row < n; row++)\n",
    "                for(column = block_size*4; column < block_size*5; column++)\n",
    "                  matrix[row][column] *= k5;\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  for(i = 0; i < n; i++)\n",
    "  {\n",
    "    for(j = 0; j < n; j++)\n",
    "      printf(\"%d\\t\", matrix[i][j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkFzAmE4BhxP"
   },
   "source": [
    "Compilando e executando novamente esse código, obtemos uma representação matricial pelas constantes k1, k2, k3, k4 e k5 de forma concorrente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EkecWU4KKvo"
   },
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpWPbNriBhxQ"
   },
   "source": [
    "Enfim durante a execução das práticas foram desenvolvidas habilidades relacionadas ao uso da API OPENMP em problemas acadêmicos de otimização de código. Atráves da primeira sessão, observa-se que o tempo de execução decrementa de acordo com o aumento do número de threads utilizadas no processo até atingir um valor ótimo.  Enquanto na segunda sessão experimentamos uma distribuição assíncrona de tarefas de forma concorrente. Portando, a prática HANDS-ON-1 foi fundamentou os estudos de programação paralela a partir do paradigma de memória compartilhada a partir de recursos computacionais multicore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbxAR_nZ3ey8"
   },
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHs1Te143ezA"
   },
   "source": [
    "[1] M. Boratto. Hands-On Supercomputing with Parallel Computing. Available: https://github.com/\n",
    "muriloboratto/Hands-On-Supercomputing-with-Parallel-Computing. 2022.\n",
    "\n",
    "[2] B. Chapman, G. Jost and R. Pas. Using OpenMP: Portable Shared Memory Parallel Programming. The\n",
    "MIT Press, 2007, USA."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-T1_3R6iCaFL",
    "BF4BYJbRK3dk",
    "gLAY9cBjxrjs",
    "0MiGCjRsrn9m",
    "tODCNPjB9eGn",
    "u9P77BloNxg7",
    "MNXuoP6ROAvo",
    "GmH0n7r1PVbM",
    "L5kUBzMXvW3z",
    "HYIuvShRPBvo",
    "7-PpumH1KDAH",
    "xbA7sVD4x_Mj"
   ],
   "name": "Relatório_Prática_Hands_On_1_Fernando_Gabriel_Jadson.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/jupyter-papers/mock-paper/blob/master/FerroicBlocks_mockup_paper_v3a.ipynb",
     "timestamp": 1659115650450
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
